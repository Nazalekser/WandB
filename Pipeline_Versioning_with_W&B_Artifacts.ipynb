{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nazalekser/WandB/blob/main/Pipeline_Versioning_with_W%26B_Artifacts.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ynh762NEch9D"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wandb/examples/blob/master/colabs/wandb-artifacts/Pipeline_Versioning_with_W&B_Artifacts.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "<!--- @wandbcode{artifacts-pipeline} -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sr30JQMich9G"
      },
      "source": [
        "<img src=\"http://wandb.me/logo-im-png\" width=\"400\" alt=\"Weights & Biases\" />\n",
        "<!--- @wandbcode{artifacts-pipeline} -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IimFBxvich9H"
      },
      "source": [
        "\n",
        "# 🏺 Artifacts 🏺\n",
        "\n",
        "In this notebook, we'll show you how to use W&B Artifacts (🏺)\n",
        "to track your ML experiment pipelines (🧪).\n",
        "Our sophisticated mathematical models predict the following result:\n",
        "\n",
        "$$\n",
        "{\\Huge\n",
        "🧪 + 🏺 = 😃}\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BZIArYYch9J"
      },
      "source": [
        "### Follow along with a [video tutorial](http://tiny.cc/wb-artifacts-video)!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-5NT_b-ch9K"
      },
      "source": [
        "### 🤔 What are Artifacts and Why Should I Care?\n",
        "\n",
        "An \"artifact\", like a Greek [amphora 🏺](https://en.wikipedia.org/wiki/Amphora),\n",
        "is a produced object -- the output of a process.\n",
        "In ML, the most important artifacts are _datasets_ and _models_.\n",
        "\n",
        "And, like the [Cross of Coronado](https://indianajones.fandom.com/wiki/Cross_of_Coronado), these important artifacts belong in a museum!\n",
        "That is, they should be cataloged and organized\n",
        "so that you, your team, and the ML community at large can learn from them.\n",
        "After all, those who don't track training are doomed to repeat it.\n",
        "\n",
        "Using our Artifacts API, you can log `Artifact`s as outputs of W&B `Run`s or use `Artifact`s as input to `Run`s, as in this diagram,\n",
        "where a training run takes in a dataset and produces a model.\n",
        "\n",
        " ![](https://gblobscdn.gitbook.com/assets%2F-Lqya5RvLedGEWPhtkjU%2F-M94QAXA-oJmE6q07_iT%2F-M94QJCXLeePzH1p_fW1%2Fsimple%20artifact%20diagram%202.png?alt=media&token=94bc438a-bd3b-414d-a4e4-aa4f6f359f21)\n",
        "\n",
        "Since one run can use another's output as an input, Artifacts and Runs together form a directed graph -- actually, a bipartite [DAG](https://en.wikipedia.org/wiki/Directed_acyclic_graph)! -- with nodes for `Artifact`s and `Run`s\n",
        "and arrows connecting `Run`s to the `Artifact`s they consume or produce."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTrmKhPJch9L"
      },
      "source": [
        "# 0️⃣ Install and Import"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubBnLx8pch9M"
      },
      "source": [
        "Artifacts are part of our Python library, starting with version `0.9.2`.\n",
        "\n",
        "Like most parts of the ML Python stack, it's available via `pip`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hgqcy06pch9N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b6ef42c-c332-41d1-b822-868f8852edc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/13.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/13.0 MB\u001b[0m \u001b[31m85.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/13.0 MB\u001b[0m \u001b[31m84.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m9.2/13.0 MB\u001b[0m \u001b[31m85.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.0/311.0 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  tree\n",
            "0 upgraded, 1 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 47.9 kB of archives.\n",
            "After this operation, 116 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tree amd64 2.0.2-1 [47.9 kB]\n",
            "Fetched 47.9 kB in 1s (54.3 kB/s)\n",
            "Selecting previously unselected package tree.\n",
            "(Reading database ... 123620 files and directories currently installed.)\n",
            "Preparing to unpack .../tree_2.0.2-1_amd64.deb ...\n",
            "Unpacking tree (2.0.2-1) ...\n",
            "Setting up tree (2.0.2-1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ],
      "source": [
        "# Compatible with wandb version 0.9.2+\n",
        "!pip install wandb -qqq\n",
        "!apt install tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pP5rVC5dch9O"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import wandb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSSNgArJch9P"
      },
      "source": [
        "# 1️⃣ Log a Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "845u22d3ch9Q"
      },
      "source": [
        "First, let's define some Artifacts.\n",
        "\n",
        "This example is based off of this PyTorch\n",
        "[\"Basic MNIST Example\"](https://github.com/pytorch/examples/tree/master/mnist/),\n",
        "but could just as easily have been done in [TensorFlow](http://wandb.me/artifacts-colab), in any other framework,\n",
        "or in pure Python.\n",
        "\n",
        "We start with the `Dataset`s:\n",
        "- a `train`ing set, for choosing the parameters,\n",
        "- a `validation` set, for choosing the hyperparameters,\n",
        "- a `test`ing set, for evaluating the final model\n",
        "\n",
        "The first cell below defines these three datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gmOXh66pch9Q"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import TensorDataset\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Ensure deterministic behavior\n",
        "torch.backends.cudnn.deterministic = True\n",
        "random.seed(0)\n",
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed_all(0)\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Data parameters\n",
        "num_classes = 10\n",
        "input_shape = (1, 28, 28)\n",
        "\n",
        "# drop slow mirror from list of MNIST mirrors\n",
        "torchvision.datasets.MNIST.mirrors = [mirror for mirror in torchvision.datasets.MNIST.mirrors\n",
        "                                      if not mirror.startswith(\"http://yann.lecun.com\")]\n",
        "\n",
        "def load(train_size=50_000):\n",
        "    \"\"\"\n",
        "    # Load the data\n",
        "    \"\"\"\n",
        "\n",
        "    # the data, split between train and test sets\n",
        "    train = torchvision.datasets.MNIST(\"./\", train=True, download=True)\n",
        "    test = torchvision.datasets.MNIST(\"./\", train=False, download=True)\n",
        "    (x_train, y_train), (x_test, y_test) = (train.data, train.targets), (test.data, test.targets)\n",
        "\n",
        "    # split off a validation set for hyperparameter tuning\n",
        "    x_train, x_val = x_train[:train_size], x_train[train_size:]\n",
        "    y_train, y_val = y_train[:train_size], y_train[train_size:]\n",
        "\n",
        "    training_set = TensorDataset(x_train, y_train)\n",
        "    validation_set = TensorDataset(x_val, y_val)\n",
        "    test_set = TensorDataset(x_test, y_test)\n",
        "\n",
        "    datasets = [training_set, validation_set, test_set]\n",
        "\n",
        "    return datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCqHGz-1ch9R"
      },
      "source": [
        "This sets up a pattern we'll see repeated in this example:\n",
        "the code to log the data as an Artifact is wrapped around the code for\n",
        "producing that data.\n",
        "In this case, the code for `load`ing the data is\n",
        "separated out from the code for `load_and_log`ging the data.\n",
        "\n",
        "This is good practice!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--hS6Wuach9S"
      },
      "source": [
        "In order to log these datasets as Artifacts,\n",
        "we just need to\n",
        "1. create a `Run` with `wandb.init`, (L4)\n",
        "2. create an `Artifact` for the dataset (L10), and\n",
        "3. save and log the associated `file`s (L20, L23).\n",
        "\n",
        "Check out the example the code cell below\n",
        "and then expand the sections afterwards for more details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfVVS_tfch9S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 644,
          "referenced_widgets": [
            "9a10867b8c544037ac5620b26de3ddd3",
            "93d1e909b82c46fabac9cffbe288d750",
            "0a5d4742726e4f03840dbd0fdf6c9f93",
            "edcdaec46efb44f7baa57b1b5783589f",
            "ec2fbacfc40f422f93a562f74cc8d5f0",
            "d8356e624ce740f5859858d1babcde61",
            "65e32ff5e78c4423a42b24765b2f38c5",
            "e8fa0cec6a384a9cb0125d9e40fdc7fc"
          ]
        },
        "outputId": "a01177f3-6fe5-489e-e31f-67ad59cfc334"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241006_110044-gelb2fbr</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/tomdom/artifacts-example/runs/gelb2fbr' target=\"_blank\">fine-glitter-1</a></strong> to <a href='https://wandb.ai/tomdom/artifacts-example' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/tomdom/artifacts-example' target=\"_blank\">https://wandb.ai/tomdom/artifacts-example</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/tomdom/artifacts-example/runs/gelb2fbr' target=\"_blank\">https://wandb.ai/tomdom/artifacts-example/runs/gelb2fbr</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:02<00:00, 4184170.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 133432.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:01<00:00, 1091813.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 4617190.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='1.075 MB of 98.207 MB uploaded\\r'), FloatProgress(value=0.010946583818457518, max=…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9a10867b8c544037ac5620b26de3ddd3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">fine-glitter-1</strong> at: <a href='https://wandb.ai/tomdom/artifacts-example/runs/gelb2fbr' target=\"_blank\">https://wandb.ai/tomdom/artifacts-example/runs/gelb2fbr</a><br/> View project at: <a href='https://wandb.ai/tomdom/artifacts-example' target=\"_blank\">https://wandb.ai/tomdom/artifacts-example</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241006_110044-gelb2fbr/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def load_and_log():\n",
        "\n",
        "    # 🚀 start a run, with a type to label it and a project it can call home\n",
        "    with wandb.init(project=\"artifacts-example\", job_type=\"load-data\") as run:\n",
        "\n",
        "        datasets = load()  # separate code for loading the datasets\n",
        "        names = [\"training\", \"validation\", \"test\"]\n",
        "\n",
        "        # 🏺 create our Artifact\n",
        "        raw_data = wandb.Artifact(\n",
        "            \"mnist-raw\", type=\"dataset\",\n",
        "            description=\"Raw MNIST dataset, split into train/val/test\",\n",
        "            metadata={\"source\": \"torchvision.datasets.MNIST\",\n",
        "                      \"sizes\": [len(dataset) for dataset in datasets]})\n",
        "\n",
        "        for name, data in zip(names, datasets):\n",
        "            # 🐣 Store a new file in the artifact, and write something into its contents.\n",
        "            with raw_data.new_file(name + \".pt\", mode=\"wb\") as file:\n",
        "                x, y = data.tensors\n",
        "                torch.save((x, y), file)\n",
        "\n",
        "        # ✍️ Save the artifact to W&B.\n",
        "        run.log_artifact(raw_data)\n",
        "\n",
        "load_and_log()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BUTRM1Wch9S"
      },
      "source": [
        "### 🚀 `wandb.init`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uT7xW8a0ch9T"
      },
      "source": [
        "\n",
        "When we make the `Run` that's going to produce the `Artifact`s,\n",
        "we need to state which `project` it belongs to.\n",
        "\n",
        "Depending on your workflow,\n",
        "a project might be as big as `car-that-drives-itself`\n",
        "or as small as `iterative-architecture-experiment-117`.\n",
        "\n",
        "> **Rule of 👍**: if you can, keep all of the `Run`s that share `Artifact`s\n",
        "inside a single project. This keeps things simple,\n",
        "but don't worry -- `Artifact`s are portable across projects!\n",
        "\n",
        "To help keep track of all the different kinds of jobs you might run,\n",
        "it's useful to provide a `job_type` when making `Runs`.\n",
        "This keeps the graph of your Artifacts nice and tidy.\n",
        "\n",
        "> **Rule of 👍**: the `job_type` should be descriptive and correspond to a single step of your pipeline. Here, we separate out `load`ing data from `preprocess`ing data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHBML9Xgch9T"
      },
      "source": [
        "### 🏺 `wandb.Artifact`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sGEBBLJch9T"
      },
      "source": [
        "\n",
        "To log something as an `Artifact`, we have to first make an `Artifact` object.\n",
        "\n",
        "Every `Artifact` has a `name` -- that's what the first argument sets.\n",
        "\n",
        "> **Rule of 👍**: the `name` should be descriptive, but easy to remember and type --\n",
        "we like to use names that are hyphen-separated and correspond to variable names in the code.\n",
        "\n",
        "It also has a `type`. Just like `job_type`s for `Run`s,\n",
        "this is used for organizing the graph of `Run`s and `Artifact`s.\n",
        "\n",
        "> **Rule of 👍**: the `type` should be simple:\n",
        "more like `dataset` or `model`\n",
        "than `mnist-data-YYYYMMDD`.\n",
        "\n",
        "You can also attach a `description` and some `metadata`, as a dictionary.\n",
        "The `metadata` just needs to be serializable to JSON.\n",
        "\n",
        "> **Rule of 👍**: the `metadata` should be as descriptive as possible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDSPowCIch9U"
      },
      "source": [
        "### 🐣 `artifact.new_file` and ✍️ `run.log_artifact`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sm0uPv3_ch9U"
      },
      "source": [
        "Once we've made an `Artifact` object, we need to add files to it.\n",
        "\n",
        "You read that right: _files_ with an _s_.\n",
        "`Artifact`s are structured like directories,\n",
        "with files and sub-directories.\n",
        "\n",
        "> **Rule of 👍**: whenever it makes sense to do so, split the contents\n",
        "of an `Artifact` up into multiple files. This will help if it comes time to scale!\n",
        "\n",
        "We use the `new_file` method\n",
        "to simultaneously write the file and attach it to the `Artifact`.\n",
        "Below, we'll use the `add_file` method,\n",
        "which separates those two steps.\n",
        "\n",
        "Once we've added all of our files, we need to `log_artifact` to [wandb.ai](https://wandb.ai).\n",
        "\n",
        "You'll notice some URLs appeared in the output,\n",
        "including one for the Run page.\n",
        "That's where you can view the results of the `Run`,\n",
        "including any `Artifact`s that got logged.\n",
        "\n",
        "We'll see some examples that make better use of the other components of the Run page below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uaHYAYTYch9U"
      },
      "source": [
        "# 2️⃣ Use a Logged Dataset Artifact"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLp8azOSch9V"
      },
      "source": [
        "`Artifact`s in W&B, unlike artifacts in museums,\n",
        "are designed to be _used_, not just stored.\n",
        "\n",
        "Let's see what that looks like.\n",
        "\n",
        "The cell below defines a pipeline step that takes in a raw dataset\n",
        "and uses it to produce a `preprocess`ed dataset:\n",
        "`normalize`d and shaped correctly.\n",
        "\n",
        "Notice again that we split out the meat of the code, `preprocess`,\n",
        "from the code that interfaces with `wandb`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kGdBlNPqch9V"
      },
      "outputs": [],
      "source": [
        "def preprocess(dataset, normalize=True, expand_dims=True):\n",
        "    \"\"\"\n",
        "    ## Prepare the data\n",
        "    \"\"\"\n",
        "    x, y = dataset.tensors\n",
        "\n",
        "    if normalize:\n",
        "        # Scale images to the [0, 1] range\n",
        "        x = x.type(torch.float32) / 255\n",
        "\n",
        "    if expand_dims:\n",
        "        # Make sure images have shape (1, 28, 28)\n",
        "        x = torch.unsqueeze(x, 1)\n",
        "\n",
        "    return TensorDataset(x, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZ9sOumvch9V"
      },
      "source": [
        "Now for the code that instruments this `preprocess` step with `wandb.Artifact` logging.\n",
        "\n",
        "Note that the example below both `use`s an `Artifact`,\n",
        "which is new,\n",
        "and `log`s it,\n",
        "which is the same as the last step.\n",
        "`Artifact`s are both the inputs and the outputs of `Run`s!\n",
        "\n",
        "We use a new `job_type`, `preprocess-data`,\n",
        "to make it clear that this is a different kind of job from the previous one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ZRGSKVDch9W"
      },
      "outputs": [],
      "source": [
        "def preprocess_and_log(steps):\n",
        "\n",
        "    with wandb.init(project=\"artifacts-example\", job_type=\"preprocess-data\") as run:\n",
        "\n",
        "        processed_data = wandb.Artifact(\n",
        "            \"mnist-preprocess\", type=\"dataset\",\n",
        "            description=\"Preprocessed MNIST dataset\",\n",
        "            metadata=steps)\n",
        "\n",
        "        # ✔️ declare which artifact we'll be using\n",
        "        raw_data_artifact = run.use_artifact('mnist-raw:latest')\n",
        "\n",
        "        # 📥 if need be, download the artifact\n",
        "        raw_dataset = raw_data_artifact.download()\n",
        "\n",
        "        for split in [\"training\", \"validation\", \"test\"]:\n",
        "            raw_split = read(raw_dataset, split)\n",
        "            processed_dataset = preprocess(raw_split, **steps)\n",
        "\n",
        "            with processed_data.new_file(split + \".pt\", mode=\"wb\") as file:\n",
        "                x, y = processed_dataset.tensors\n",
        "                torch.save((x, y), file)\n",
        "\n",
        "        run.log_artifact(processed_data)\n",
        "\n",
        "\n",
        "def read(data_dir, split):\n",
        "    filename = split + \".pt\"\n",
        "    x, y = torch.load(os.path.join(data_dir, filename))\n",
        "\n",
        "    return TensorDataset(x, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGoZ_oYYch9W"
      },
      "source": [
        "One thing to notice here is that the `steps` of the preprocessing\n",
        "are saved with the `preprocessed_data` as `metadata`.\n",
        "\n",
        "If you're trying to make your experiments reproducible,\n",
        "capturing lots of metadata is a good idea!\n",
        "\n",
        "Also, even though our dataset is a \"`large artifact`\",\n",
        "the `download` step is done in much less than a second.\n",
        "\n",
        "Expand the markdown cell below for details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L0V6zTMZch9X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297,
          "referenced_widgets": [
            "ce2b1d34bd21418ba0de0fad005820ae",
            "80face98f71c4e1096987b8b1a7c2908",
            "7e9f4becee8942c7bfee583ea63ab0c8",
            "efc74ee2e30c4c4aaf8b803fe26b85b2",
            "0edd187e40f949f6949409e116a66bbe",
            "9db2630765534d65b9c8b4bbc46fed3d",
            "d9a24284eac340d28aa18834c9a9b9f6",
            "b246166afe70458ebe8352261edbaedf"
          ]
        },
        "outputId": "0a0e8210-1f39-4b0e-ffe9-215ff935f278"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtoxareu\u001b[0m (\u001b[33mtomdom\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241006_110108-c762ccdk</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/tomdom/artifacts-example/runs/c762ccdk' target=\"_blank\">fragrant-pyramid-2</a></strong> to <a href='https://wandb.ai/tomdom/artifacts-example' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/tomdom/artifacts-example' target=\"_blank\">https://wandb.ai/tomdom/artifacts-example</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/tomdom/artifacts-example/runs/c762ccdk' target=\"_blank\">https://wandb.ai/tomdom/artifacts-example/runs/c762ccdk</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact mnist-raw:latest, 98.19MB. 3 files... \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   3 of 3 files downloaded.  \n",
            "Done. 0:0:6.0\n",
            "<ipython-input-6-0a1d75d25913>:29: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  x, y = torch.load(os.path.join(data_dir, filename))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='1.122 MB of 210.359 MB uploaded\\r'), FloatProgress(value=0.005331858715502539, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ce2b1d34bd21418ba0de0fad005820ae"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">fragrant-pyramid-2</strong> at: <a href='https://wandb.ai/tomdom/artifacts-example/runs/c762ccdk' target=\"_blank\">https://wandb.ai/tomdom/artifacts-example/runs/c762ccdk</a><br/> View project at: <a href='https://wandb.ai/tomdom/artifacts-example' target=\"_blank\">https://wandb.ai/tomdom/artifacts-example</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241006_110108-c762ccdk/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "steps = {\"normalize\": True,\n",
        "         \"expand_dims\": True}\n",
        "\n",
        "preprocess_and_log(steps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_r3ttLG9ch9X"
      },
      "source": [
        "### ✔️ `run.use_artifact`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPki_XTHch9X"
      },
      "source": [
        "These steps are simpler. The consumer just needs to know the `name` of the `Artifact`, plus a bit more.\n",
        "\n",
        "That \"bit more\" is the `alias` of the particular version of the `Artifact` you want.\n",
        "\n",
        "By default, the last version to be uploaded is tagged `latest`.\n",
        "Otherwise, you can pick older versions with `v0`/`v1`, etc.,\n",
        "or you can provide your own aliases, like `best` or `jit-script`.\n",
        "Just like [Docker Hub](https://hub.docker.com/) tags,\n",
        "aliases are separated from names with `:`,\n",
        "so the `Artifact` we want is `mnist-raw:latest`.\n",
        "\n",
        "> **Rule of 👍**: Keep aliases short and sweet.\n",
        "Use custom `alias`es like `latest` or `best` when you want an `Artifact`\n",
        "that satisifies some property"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzmQmVh0ch9Y"
      },
      "source": [
        "### 📥 `artifact.download`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LM3vUGMVch9Y"
      },
      "source": [
        "\n",
        "Now, you may be worrying about the `download` call.\n",
        "If we download another copy, won't that double the burden on memory?\n",
        "\n",
        "Don't worry friend. Before we actually download anything,\n",
        "we check to see if the right version is available locally.\n",
        "This uses the same technology that underlies [torrenting](https://en.wikipedia.org/wiki/Torrent_file) and [version control with `git`](https://blog.thoughtram.io/git/2014/11/18/the-anatomy-of-a-git-commit.html): hashing.\n",
        "\n",
        "As `Artifact`s are created and logged,\n",
        "a folder called `artifacts` in the working directory\n",
        "will start to fill with sub-directories,\n",
        "one for each `Artifact`.\n",
        "Check out its contents with `!tree artifacts`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UBt-9M3sch9Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "011f48c4-7193-4db0-bc6b-b3e5871b3431"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[01;34martifacts\u001b[0m\n",
            "└── \u001b[01;34mmnist-raw:v0\u001b[0m\n",
            "    ├── \u001b[00mtest.pt\u001b[0m\n",
            "    ├── \u001b[00mtraining.pt\u001b[0m\n",
            "    └── \u001b[00mvalidation.pt\u001b[0m\n",
            "\n",
            "1 directory, 3 files\n"
          ]
        }
      ],
      "source": [
        "!tree artifacts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCQ74-tych9Z"
      },
      "source": [
        "### 🌐 The Artifacts page on [wandb.ai](https://wandb.ai)\n",
        "\n",
        "Now that we've logged and used an `Artifact`,\n",
        "let's check out the Artifacts tab on the Run page.\n",
        "\n",
        "Navigate to the Run page URL from the `wandb` output\n",
        "and select the \"Artifacts\" tab from the left sidebar\n",
        "(it's the one with the database icon,\n",
        "which looks like three hockey pucks stacked on top of one another).\n",
        "\n",
        "Click a row in either the \"Input Artifacts\" table\n",
        "or in the \"Output Artifacts\" table,\n",
        "then check out the tabs (\"Overview\", \"Metadata\")\n",
        "to see everything logged about the `Artifact`.\n",
        "\n",
        "We particularly like the \"Graph View\".\n",
        "By default, it shows a graph\n",
        "with the `type`s of `Artifact`s\n",
        "and the `job_type`s of `Run` as the two types of nodes,\n",
        "with arrows to represent consumption and production."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8d0VzVjch9Z"
      },
      "source": [
        "# 3️⃣ Log a Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLfoD0SQch9Z"
      },
      "source": [
        "That's enough to see how the API for `Artifact`s works,\n",
        "but let's follow this example through to the end of the pipeline\n",
        "so we can see how `Artifact`s can improve your ML workflow.\n",
        "\n",
        "This first cell here builds a DNN `model` in PyTorch -- a really simple ConvNet.\n",
        "\n",
        "We'll start by just initializing the `model`, not training it.\n",
        "That way, we can repeat the training while keeping everything else constant."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8oueq7hhch9a"
      },
      "outputs": [],
      "source": [
        "from math import floor\n",
        "\n",
        "import torch.nn as nn\n",
        "\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self, hidden_layer_sizes=[32, 64],\n",
        "                  kernel_sizes=[3],\n",
        "                  activation=\"ReLU\",\n",
        "                  pool_sizes=[2],\n",
        "                  dropout=0.5,\n",
        "                  num_classes=num_classes,\n",
        "                  input_shape=input_shape):\n",
        "\n",
        "        super(ConvNet, self).__init__()\n",
        "\n",
        "        self.layer1 = nn.Sequential(\n",
        "              nn.Conv2d(in_channels=input_shape[0], out_channels=hidden_layer_sizes[0], kernel_size=kernel_sizes[0]),\n",
        "              getattr(nn, activation)(),\n",
        "              nn.MaxPool2d(kernel_size=pool_sizes[0])\n",
        "        )\n",
        "        self.layer2 = nn.Sequential(\n",
        "              nn.Conv2d(in_channels=hidden_layer_sizes[0], out_channels=hidden_layer_sizes[-1], kernel_size=kernel_sizes[-1]),\n",
        "              getattr(nn, activation)(),\n",
        "              nn.MaxPool2d(kernel_size=pool_sizes[-1])\n",
        "        )\n",
        "        self.layer3 = nn.Sequential(\n",
        "              nn.Flatten(),\n",
        "              nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "        fc_input_dims = floor((input_shape[1] - kernel_sizes[0] + 1) / pool_sizes[0]) # layer 1 output size\n",
        "        fc_input_dims = floor((fc_input_dims - kernel_sizes[-1] + 1) / pool_sizes[-1]) # layer 2 output size\n",
        "        fc_input_dims = fc_input_dims*fc_input_dims*hidden_layer_sizes[-1] # layer 3 output size\n",
        "\n",
        "        self.fc = nn.Linear(fc_input_dims, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mS_4o6nch9a"
      },
      "source": [
        "Here, we're using W&B to track the run,\n",
        "and so using the [`wandb.config`](https://colab.research.google.com/github/wandb/examples/blob/master/colabs/wandb-config/Configs_in_W%26B.ipynb)\n",
        "object to store all of the hyperparameters.\n",
        "\n",
        "The `dict`ionary version of that `config` object is a really useful piece of `metadata`, so make sure to include it!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7LrVffU1ch9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "cb863233033f4440bf8018dd5325db79",
            "ad573ae8347a458e9dd9eaa05be9ef07",
            "10089b3fb8374a47b86949a0adb682c0",
            "f7caecee87b34508baa19d98fb7340f6",
            "ae598b72c6714146b6ae61e08192b68c",
            "415cbbb9a3dd4b4dacf7aba2f3aebada",
            "ad0b4610179e45e5a1dd56e596d4dcca",
            "24d94887e9544356a99c5640f9da0d59"
          ]
        },
        "outputId": "8646bc4a-ba88-4636-c336-210071104707"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241006_110135-t16to3v0</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/tomdom/artifacts-example/runs/t16to3v0' target=\"_blank\">rare-dew-3</a></strong> to <a href='https://wandb.ai/tomdom/artifacts-example' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/tomdom/artifacts-example' target=\"_blank\">https://wandb.ai/tomdom/artifacts-example</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/tomdom/artifacts-example/runs/t16to3v0' target=\"_blank\">https://wandb.ai/tomdom/artifacts-example/runs/t16to3v0</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.147 MB of 0.147 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cb863233033f4440bf8018dd5325db79"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">rare-dew-3</strong> at: <a href='https://wandb.ai/tomdom/artifacts-example/runs/t16to3v0' target=\"_blank\">https://wandb.ai/tomdom/artifacts-example/runs/t16to3v0</a><br/> View project at: <a href='https://wandb.ai/tomdom/artifacts-example' target=\"_blank\">https://wandb.ai/tomdom/artifacts-example</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241006_110135-t16to3v0/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def build_model_and_log(config):\n",
        "    with wandb.init(project=\"artifacts-example\", job_type=\"initialize\", config=config) as run:\n",
        "        config = wandb.config\n",
        "\n",
        "        model = ConvNet(**config)\n",
        "\n",
        "        model_artifact = wandb.Artifact(\n",
        "            \"convnet\", type=\"model\",\n",
        "            description=\"Simple AlexNet style CNN\",\n",
        "            metadata=dict(config))\n",
        "\n",
        "        torch.save(model.state_dict(), \"initialized_model.pth\")\n",
        "        # ➕ another way to add a file to an Artifact\n",
        "        model_artifact.add_file(\"initialized_model.pth\")\n",
        "\n",
        "        wandb.save(\"initialized_model.pth\")\n",
        "\n",
        "        run.log_artifact(model_artifact)\n",
        "\n",
        "model_config = {\"hidden_layer_sizes\": [32, 64],\n",
        "                \"kernel_sizes\": [3],\n",
        "                \"activation\": \"ReLU\",\n",
        "                \"pool_sizes\": [2],\n",
        "                \"dropout\": 0.5,\n",
        "                \"num_classes\": 10}\n",
        "\n",
        "build_model_and_log(model_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GmRBtawch9l"
      },
      "source": [
        "### ➕ `artifact.add_file`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQZe0RY2ch9l"
      },
      "source": [
        "\n",
        "Instead of simultaneously writing a `new_file` and adding it to the `Artifact`,\n",
        "as in the dataset logging examples,\n",
        "we can also write files in one step\n",
        "(here, `torch.save`)\n",
        "and then `add` them to the `Artifact` in another.\n",
        "\n",
        "> **Rule of 👍**: use `new_file` when you can, to prevent duplication."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQZvSCB4ch9l"
      },
      "source": [
        "# 4️⃣ Use a Logged Model Artifact"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAVeMCgPch9m"
      },
      "source": [
        "Just like we could call `use_artifact` on a `dataset`,\n",
        "we can call it on our `initialized_model`\n",
        "to use it in another `Run`.\n",
        "\n",
        "This time, let's `train` the `model`.\n",
        "\n",
        "For more details, check out our Colab on\n",
        "[instrumenting W&B with PyTorch](http://wandb.me/pytorch-colab)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BnSDv1hych9m"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def train(model, train_loader, valid_loader, config):\n",
        "    optimizer = getattr(torch.optim, config.optimizer)(model.parameters())\n",
        "    model.train()\n",
        "    example_ct = 0\n",
        "    for epoch in range(config.epochs):\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = F.cross_entropy(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            example_ct += len(data)\n",
        "\n",
        "            if batch_idx % config.batch_log_interval == 0:\n",
        "                print('Train Epoch: {} [{}/{} ({:.0%})]\\tLoss: {:.6f}'.format(\n",
        "                    epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                    batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "                train_log(loss, example_ct, epoch)\n",
        "\n",
        "        # evaluate the model on the validation set at each epoch\n",
        "        loss, accuracy = test(model, valid_loader)\n",
        "        test_log(loss, accuracy, example_ct, epoch)\n",
        "\n",
        "\n",
        "def test(model, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.cross_entropy(output, target, reduction='sum')  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    accuracy = 100. * correct / len(test_loader.dataset)\n",
        "\n",
        "    return test_loss, accuracy\n",
        "\n",
        "\n",
        "def train_log(loss, example_ct, epoch):\n",
        "    loss = float(loss)\n",
        "\n",
        "    # where the magic happens\n",
        "    wandb.log({\"epoch\": epoch, \"train/loss\": loss}, step=example_ct)\n",
        "    print(f\"Loss after \" + str(example_ct).zfill(5) + f\" examples: {loss:.3f}\")\n",
        "\n",
        "\n",
        "def test_log(loss, accuracy, example_ct, epoch):\n",
        "    loss = float(loss)\n",
        "    accuracy = float(accuracy)\n",
        "\n",
        "    # where the magic happens\n",
        "    wandb.log({\"epoch\": epoch, \"validation/loss\": loss, \"validation/accuracy\": accuracy}, step=example_ct)\n",
        "    print(f\"Loss/accuracy after \" + str(example_ct).zfill(5) + f\" examples: {loss:.3f}/{accuracy:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_gzO2OQch9n"
      },
      "source": [
        "We'll run two separate `Artifact`-producing `Run`s this time.\n",
        "\n",
        "Once the first finishes `train`ing the `model`,\n",
        "the `second` will consume the `trained-model` `Artifact`\n",
        "by `evaluate`ing its performance on the `test_dataset`.\n",
        "\n",
        "Also, we'll pull out the 32 examples on which the network gets the most confused --\n",
        "on which the `categorical_crossentropy` is highest.\n",
        "\n",
        "This is a good way to diagnose issues with your dataset and your model!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "juVovDQlch9n"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, test_loader):\n",
        "    \"\"\"\n",
        "    ## Evaluate the trained model\n",
        "    \"\"\"\n",
        "\n",
        "    loss, accuracy = test(model, test_loader)\n",
        "    highest_losses, hardest_examples, true_labels, predictions = get_hardest_k_examples(model, test_loader.dataset)\n",
        "\n",
        "    return loss, accuracy, highest_losses, hardest_examples, true_labels, predictions\n",
        "\n",
        "def get_hardest_k_examples(model, testing_set, k=32):\n",
        "    model.eval()\n",
        "\n",
        "    loader = DataLoader(testing_set, 1, shuffle=False)\n",
        "\n",
        "    # get the losses and predictions for each item in the dataset\n",
        "    losses = None\n",
        "    predictions = None\n",
        "    with torch.no_grad():\n",
        "        for data, target in loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            loss = F.cross_entropy(output, target)\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "\n",
        "            if losses is None:\n",
        "                losses = loss.view((1, 1))\n",
        "                predictions = pred\n",
        "            else:\n",
        "                losses = torch.cat((losses, loss.view((1, 1))), 0)\n",
        "                predictions = torch.cat((predictions, pred), 0)\n",
        "\n",
        "    argsort_loss = torch.argsort(losses, dim=0).cpu()\n",
        "\n",
        "    highest_k_losses = losses[argsort_loss[-k:]]\n",
        "    hardest_k_examples = testing_set[argsort_loss[-k:]][0]\n",
        "    true_labels = testing_set[argsort_loss[-k:]][1]\n",
        "    predicted_labels = predictions[argsort_loss[-k:]]\n",
        "\n",
        "    return highest_k_losses, hardest_k_examples, true_labels, predicted_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrWfRWS1ch9o"
      },
      "source": [
        "These logging functions don't add any new `Artifact` features,\n",
        "so we won't comment on them:\n",
        "we're just `use`ing, `download`ing,\n",
        "and `log`ging `Artifact`s."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ogqd3zC8ch9o"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def train_and_log(config):\n",
        "\n",
        "    with wandb.init(project=\"artifacts-example\", job_type=\"train\", config=config) as run:\n",
        "        config = wandb.config\n",
        "\n",
        "        data = run.use_artifact('mnist-preprocess:latest')\n",
        "        data_dir = data.download()\n",
        "\n",
        "        training_dataset =  read(data_dir, \"training\")\n",
        "        validation_dataset = read(data_dir, \"validation\")\n",
        "\n",
        "        train_loader = DataLoader(training_dataset, batch_size=config.batch_size)\n",
        "        validation_loader = DataLoader(validation_dataset, batch_size=config.batch_size)\n",
        "\n",
        "        model_artifact = run.use_artifact(\"convnet:latest\")\n",
        "        model_dir = model_artifact.download()\n",
        "        model_path = os.path.join(model_dir, \"initialized_model.pth\")\n",
        "        model_config = model_artifact.metadata\n",
        "        config.update(model_config)\n",
        "\n",
        "        model = ConvNet(**model_config)\n",
        "        model.load_state_dict(torch.load(model_path))\n",
        "        model = model.to(device)\n",
        "\n",
        "        train(model, train_loader, validation_loader, config)\n",
        "\n",
        "        model_artifact = wandb.Artifact(\n",
        "            \"trained-model\", type=\"model\",\n",
        "            description=\"Trained NN model\",\n",
        "            metadata=dict(model_config))\n",
        "\n",
        "        torch.save(model.state_dict(), \"trained_model.pth\")\n",
        "        model_artifact.add_file(\"trained_model.pth\")\n",
        "        wandb.save(\"trained_model.pth\")\n",
        "\n",
        "        run.log_artifact(model_artifact)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def evaluate_and_log(config=None):\n",
        "\n",
        "    with wandb.init(project=\"artifacts-example\", job_type=\"report\", config=config) as run:\n",
        "        data = run.use_artifact('mnist-preprocess:latest')\n",
        "        data_dir = data.download()\n",
        "        testing_set = read(data_dir, \"test\")\n",
        "\n",
        "        test_loader = torch.utils.data.DataLoader(testing_set, batch_size=128, shuffle=False)\n",
        "\n",
        "        model_artifact = run.use_artifact(\"trained-model:latest\")\n",
        "        model_dir = model_artifact.download()\n",
        "        model_path = os.path.join(model_dir, \"trained_model.pth\")\n",
        "        model_config = model_artifact.metadata\n",
        "\n",
        "        model = ConvNet(**model_config)\n",
        "        model.load_state_dict(torch.load(model_path))\n",
        "        model.to(device)\n",
        "\n",
        "        loss, accuracy, highest_losses, hardest_examples, true_labels, preds = evaluate(model, test_loader)\n",
        "\n",
        "        run.summary.update({\"loss\": loss, \"accuracy\": accuracy})\n",
        "\n",
        "        wandb.log({\"high-loss-examples\":\n",
        "            [wandb.Image(hard_example, caption=str(int(pred)) + \",\" +  str(int(label)))\n",
        "             for hard_example, pred, label in zip(hardest_examples, preds, true_labels)]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yfoWyNAZch9p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "6f40d2162201456194b8bf7157126dec",
            "5754ce43613e48c8b150e0f995e53790",
            "918799ce377946bc99bef56be4bc2be9",
            "8705ed3d9fc449439788f193eff9dbb0",
            "015769be45ce4792a9ff37c78ff379a4",
            "f577f7748c35489aa15930476c4407fa",
            "de006a676c3f481eae25f4ed4286a383",
            "3ccf7a2a31154c339b793ecf48173068",
            "5c136a77191c4bcf8d8c64824ff091f3",
            "db5dde5ee28540c5b2e201249f0db271",
            "c33a853aa24f4d99bc464f832221539d",
            "4317dd43dd7e4b8f8b338cff9f623303",
            "bbb04154da694df195782fde18dc0726",
            "be51d8aa88cd4993a822c732f6a41f94",
            "c1b7727570104e49bc7f5152f6d86ec4",
            "78872de69daa4a38a48f58ce59e55037"
          ]
        },
        "outputId": "7fbdc4e0-f90c-42fc-b3c9-52c066a9ea31"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241006_110144-5zw5rzhx</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/tomdom/artifacts-example/runs/5zw5rzhx' target=\"_blank\">laced-pine-4</a></strong> to <a href='https://wandb.ai/tomdom/artifacts-example' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/tomdom/artifacts-example' target=\"_blank\">https://wandb.ai/tomdom/artifacts-example</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/tomdom/artifacts-example/runs/5zw5rzhx' target=\"_blank\">https://wandb.ai/tomdom/artifacts-example/runs/5zw5rzhx</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact mnist-preprocess:latest, 210.35MB. 3 files... \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   3 of 3 files downloaded.  \n",
            "Done. 0:0:10.8\n",
            "<ipython-input-6-0a1d75d25913>:29: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  x, y = torch.load(os.path.join(data_dir, filename))\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
            "<ipython-input-13-1710630121f3>:24: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 0 [0/50000 (0%)]\tLoss: 2.312536\n",
            "Loss after 00128 examples: 2.313\n",
            "Train Epoch: 0 [3200/50000 (6%)]\tLoss: 1.016427\n",
            "Loss after 03328 examples: 1.016\n",
            "Train Epoch: 0 [6400/50000 (13%)]\tLoss: 0.543447\n",
            "Loss after 06528 examples: 0.543\n",
            "Train Epoch: 0 [9600/50000 (19%)]\tLoss: 0.295397\n",
            "Loss after 09728 examples: 0.295\n",
            "Train Epoch: 0 [12800/50000 (26%)]\tLoss: 0.240047\n",
            "Loss after 12928 examples: 0.240\n",
            "Train Epoch: 0 [16000/50000 (32%)]\tLoss: 0.339060\n",
            "Loss after 16128 examples: 0.339\n",
            "Train Epoch: 0 [19200/50000 (38%)]\tLoss: 0.196616\n",
            "Loss after 19328 examples: 0.197\n",
            "Train Epoch: 0 [22400/50000 (45%)]\tLoss: 0.194720\n",
            "Loss after 22528 examples: 0.195\n",
            "Train Epoch: 0 [25600/50000 (51%)]\tLoss: 0.137736\n",
            "Loss after 25728 examples: 0.138\n",
            "Train Epoch: 0 [28800/50000 (58%)]\tLoss: 0.132933\n",
            "Loss after 28928 examples: 0.133\n",
            "Train Epoch: 0 [32000/50000 (64%)]\tLoss: 0.222700\n",
            "Loss after 32128 examples: 0.223\n",
            "Train Epoch: 0 [35200/50000 (70%)]\tLoss: 0.189966\n",
            "Loss after 35328 examples: 0.190\n",
            "Train Epoch: 0 [38400/50000 (77%)]\tLoss: 0.111620\n",
            "Loss after 38528 examples: 0.112\n",
            "Train Epoch: 0 [41600/50000 (83%)]\tLoss: 0.119710\n",
            "Loss after 41728 examples: 0.120\n",
            "Train Epoch: 0 [44800/50000 (90%)]\tLoss: 0.225979\n",
            "Loss after 44928 examples: 0.226\n",
            "Train Epoch: 0 [48000/50000 (96%)]\tLoss: 0.100768\n",
            "Loss after 48128 examples: 0.101\n",
            "Loss/accuracy after 50000 examples: 0.094/97.490\n",
            "Train Epoch: 1 [0/50000 (0%)]\tLoss: 0.118347\n",
            "Loss after 50128 examples: 0.118\n",
            "Train Epoch: 1 [3200/50000 (6%)]\tLoss: 0.070442\n",
            "Loss after 53328 examples: 0.070\n",
            "Train Epoch: 1 [6400/50000 (13%)]\tLoss: 0.112362\n",
            "Loss after 56528 examples: 0.112\n",
            "Train Epoch: 1 [9600/50000 (19%)]\tLoss: 0.073480\n",
            "Loss after 59728 examples: 0.073\n",
            "Train Epoch: 1 [12800/50000 (26%)]\tLoss: 0.060022\n",
            "Loss after 62928 examples: 0.060\n",
            "Train Epoch: 1 [16000/50000 (32%)]\tLoss: 0.091994\n",
            "Loss after 66128 examples: 0.092\n",
            "Train Epoch: 1 [19200/50000 (38%)]\tLoss: 0.064658\n",
            "Loss after 69328 examples: 0.065\n",
            "Train Epoch: 1 [22400/50000 (45%)]\tLoss: 0.059957\n",
            "Loss after 72528 examples: 0.060\n",
            "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 0.079567\n",
            "Loss after 75728 examples: 0.080\n",
            "Train Epoch: 1 [28800/50000 (58%)]\tLoss: 0.037339\n",
            "Loss after 78928 examples: 0.037\n",
            "Train Epoch: 1 [32000/50000 (64%)]\tLoss: 0.130031\n",
            "Loss after 82128 examples: 0.130\n",
            "Train Epoch: 1 [35200/50000 (70%)]\tLoss: 0.066711\n",
            "Loss after 85328 examples: 0.067\n",
            "Train Epoch: 1 [38400/50000 (77%)]\tLoss: 0.090664\n",
            "Loss after 88528 examples: 0.091\n",
            "Train Epoch: 1 [41600/50000 (83%)]\tLoss: 0.048247\n",
            "Loss after 91728 examples: 0.048\n",
            "Train Epoch: 1 [44800/50000 (90%)]\tLoss: 0.097168\n",
            "Loss after 94928 examples: 0.097\n",
            "Train Epoch: 1 [48000/50000 (96%)]\tLoss: 0.058256\n",
            "Loss after 98128 examples: 0.058\n",
            "Loss/accuracy after 100000 examples: 0.063/98.140\n",
            "Train Epoch: 2 [0/50000 (0%)]\tLoss: 0.066787\n",
            "Loss after 100128 examples: 0.067\n",
            "Train Epoch: 2 [3200/50000 (6%)]\tLoss: 0.027623\n",
            "Loss after 103328 examples: 0.028\n",
            "Train Epoch: 2 [6400/50000 (13%)]\tLoss: 0.099428\n",
            "Loss after 106528 examples: 0.099\n",
            "Train Epoch: 2 [9600/50000 (19%)]\tLoss: 0.036179\n",
            "Loss after 109728 examples: 0.036\n",
            "Train Epoch: 2 [12800/50000 (26%)]\tLoss: 0.048890\n",
            "Loss after 112928 examples: 0.049\n",
            "Train Epoch: 2 [16000/50000 (32%)]\tLoss: 0.050217\n",
            "Loss after 116128 examples: 0.050\n",
            "Train Epoch: 2 [19200/50000 (38%)]\tLoss: 0.038872\n",
            "Loss after 119328 examples: 0.039\n",
            "Train Epoch: 2 [22400/50000 (45%)]\tLoss: 0.029957\n",
            "Loss after 122528 examples: 0.030\n",
            "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 0.055318\n",
            "Loss after 125728 examples: 0.055\n",
            "Train Epoch: 2 [28800/50000 (58%)]\tLoss: 0.019568\n",
            "Loss after 128928 examples: 0.020\n",
            "Train Epoch: 2 [32000/50000 (64%)]\tLoss: 0.093243\n",
            "Loss after 132128 examples: 0.093\n",
            "Train Epoch: 2 [35200/50000 (70%)]\tLoss: 0.058261\n",
            "Loss after 135328 examples: 0.058\n",
            "Train Epoch: 2 [38400/50000 (77%)]\tLoss: 0.085433\n",
            "Loss after 138528 examples: 0.085\n",
            "Train Epoch: 2 [41600/50000 (83%)]\tLoss: 0.037635\n",
            "Loss after 141728 examples: 0.038\n",
            "Train Epoch: 2 [44800/50000 (90%)]\tLoss: 0.056549\n",
            "Loss after 144928 examples: 0.057\n",
            "Train Epoch: 2 [48000/50000 (96%)]\tLoss: 0.040943\n",
            "Loss after 148128 examples: 0.041\n",
            "Loss/accuracy after 150000 examples: 0.055/98.420\n",
            "Train Epoch: 3 [0/50000 (0%)]\tLoss: 0.049036\n",
            "Loss after 150128 examples: 0.049\n",
            "Train Epoch: 3 [3200/50000 (6%)]\tLoss: 0.020155\n",
            "Loss after 153328 examples: 0.020\n",
            "Train Epoch: 3 [6400/50000 (13%)]\tLoss: 0.095541\n",
            "Loss after 156528 examples: 0.096\n",
            "Train Epoch: 3 [9600/50000 (19%)]\tLoss: 0.022203\n",
            "Loss after 159728 examples: 0.022\n",
            "Train Epoch: 3 [12800/50000 (26%)]\tLoss: 0.035108\n",
            "Loss after 162928 examples: 0.035\n",
            "Train Epoch: 3 [16000/50000 (32%)]\tLoss: 0.038146\n",
            "Loss after 166128 examples: 0.038\n",
            "Train Epoch: 3 [19200/50000 (38%)]\tLoss: 0.027009\n",
            "Loss after 169328 examples: 0.027\n",
            "Train Epoch: 3 [22400/50000 (45%)]\tLoss: 0.018159\n",
            "Loss after 172528 examples: 0.018\n",
            "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 0.047424\n",
            "Loss after 175728 examples: 0.047\n",
            "Train Epoch: 3 [28800/50000 (58%)]\tLoss: 0.011278\n",
            "Loss after 178928 examples: 0.011\n",
            "Train Epoch: 3 [32000/50000 (64%)]\tLoss: 0.063865\n",
            "Loss after 182128 examples: 0.064\n",
            "Train Epoch: 3 [35200/50000 (70%)]\tLoss: 0.055050\n",
            "Loss after 185328 examples: 0.055\n",
            "Train Epoch: 3 [38400/50000 (77%)]\tLoss: 0.077180\n",
            "Loss after 188528 examples: 0.077\n",
            "Train Epoch: 3 [41600/50000 (83%)]\tLoss: 0.029739\n",
            "Loss after 191728 examples: 0.030\n",
            "Train Epoch: 3 [44800/50000 (90%)]\tLoss: 0.036135\n",
            "Loss after 194928 examples: 0.036\n",
            "Train Epoch: 3 [48000/50000 (96%)]\tLoss: 0.027451\n",
            "Loss after 198128 examples: 0.027\n",
            "Loss/accuracy after 200000 examples: 0.051/98.520\n",
            "Train Epoch: 4 [0/50000 (0%)]\tLoss: 0.037085\n",
            "Loss after 200128 examples: 0.037\n",
            "Train Epoch: 4 [3200/50000 (6%)]\tLoss: 0.018228\n",
            "Loss after 203328 examples: 0.018\n",
            "Train Epoch: 4 [6400/50000 (13%)]\tLoss: 0.093834\n",
            "Loss after 206528 examples: 0.094\n",
            "Train Epoch: 4 [9600/50000 (19%)]\tLoss: 0.015658\n",
            "Loss after 209728 examples: 0.016\n",
            "Train Epoch: 4 [12800/50000 (26%)]\tLoss: 0.025457\n",
            "Loss after 212928 examples: 0.025\n",
            "Train Epoch: 4 [16000/50000 (32%)]\tLoss: 0.028723\n",
            "Loss after 216128 examples: 0.029\n",
            "Train Epoch: 4 [19200/50000 (38%)]\tLoss: 0.023222\n",
            "Loss after 219328 examples: 0.023\n",
            "Train Epoch: 4 [22400/50000 (45%)]\tLoss: 0.015843\n",
            "Loss after 222528 examples: 0.016\n",
            "Train Epoch: 4 [25600/50000 (51%)]\tLoss: 0.046216\n",
            "Loss after 225728 examples: 0.046\n",
            "Train Epoch: 4 [28800/50000 (58%)]\tLoss: 0.007720\n",
            "Loss after 228928 examples: 0.008\n",
            "Train Epoch: 4 [32000/50000 (64%)]\tLoss: 0.048485\n",
            "Loss after 232128 examples: 0.048\n",
            "Train Epoch: 4 [35200/50000 (70%)]\tLoss: 0.043970\n",
            "Loss after 235328 examples: 0.044\n",
            "Train Epoch: 4 [38400/50000 (77%)]\tLoss: 0.066505\n",
            "Loss after 238528 examples: 0.067\n",
            "Train Epoch: 4 [41600/50000 (83%)]\tLoss: 0.024618\n",
            "Loss after 241728 examples: 0.025\n",
            "Train Epoch: 4 [44800/50000 (90%)]\tLoss: 0.024293\n",
            "Loss after 244928 examples: 0.024\n",
            "Train Epoch: 4 [48000/50000 (96%)]\tLoss: 0.017629\n",
            "Loss after 248128 examples: 0.018\n",
            "Loss/accuracy after 250000 examples: 0.048/98.640\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.292 MB of 0.292 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6f40d2162201456194b8bf7157126dec"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▅▅▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆████</td></tr><tr><td>train/loss</td><td>█▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>validation/accuracy</td><td>▁▅▇▇█</td></tr><tr><td>validation/loss</td><td>█▃▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>4</td></tr><tr><td>train/loss</td><td>0.01763</td></tr><tr><td>validation/accuracy</td><td>98.64</td></tr><tr><td>validation/loss</td><td>0.04769</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">laced-pine-4</strong> at: <a href='https://wandb.ai/tomdom/artifacts-example/runs/5zw5rzhx' target=\"_blank\">https://wandb.ai/tomdom/artifacts-example/runs/5zw5rzhx</a><br/> View project at: <a href='https://wandb.ai/tomdom/artifacts-example' target=\"_blank\">https://wandb.ai/tomdom/artifacts-example</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241006_110144-5zw5rzhx/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241006_110218-b4y0g428</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/tomdom/artifacts-example/runs/b4y0g428' target=\"_blank\">brisk-monkey-5</a></strong> to <a href='https://wandb.ai/tomdom/artifacts-example' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/tomdom/artifacts-example' target=\"_blank\">https://wandb.ai/tomdom/artifacts-example</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/tomdom/artifacts-example/runs/b4y0g428' target=\"_blank\">https://wandb.ai/tomdom/artifacts-example/runs/b4y0g428</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact mnist-preprocess:latest, 210.35MB. 3 files... \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   3 of 3 files downloaded.  \n",
            "Done. 0:0:0.6\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
            "<ipython-input-13-1710630121f3>:58: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.029 MB of 0.029 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5c136a77191c4bcf8d8c64824ff091f3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>98.88</td></tr><tr><td>loss</td><td>0.03584</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">brisk-monkey-5</strong> at: <a href='https://wandb.ai/tomdom/artifacts-example/runs/b4y0g428' target=\"_blank\">https://wandb.ai/tomdom/artifacts-example/runs/b4y0g428</a><br/> View project at: <a href='https://wandb.ai/tomdom/artifacts-example' target=\"_blank\">https://wandb.ai/tomdom/artifacts-example</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 32 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241006_110218-b4y0g428/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "train_config = {\"batch_size\": 128,\n",
        "                \"epochs\": 5,\n",
        "                \"batch_log_interval\": 25,\n",
        "                \"optimizer\": \"Adam\"}\n",
        "\n",
        "model = train_and_log(train_config)\n",
        "evaluate_and_log()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tw8l3Uuech9p"
      },
      "source": [
        "### 🔁 The Graph View\n",
        "\n",
        "Notice that we changed the `type` of the `Artifact`:\n",
        "these `Run`s used a `model`, rather than `dataset`.\n",
        "`Run`s that produce `model`s will be separated\n",
        "from those that produce `dataset`s in the graph view on the Artifacts page.\n",
        "\n",
        "Go check it out! As before, you'll want to head to the Run page,\n",
        "select the \"Artifacts\" tab from the left sidebar,\n",
        "pick an `Artifact`,\n",
        "and then click the \"Graph View\" tab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGvEknZCch9p"
      },
      "source": [
        "\n",
        "### 💣 Exploded Graphs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXdxsocSch9q"
      },
      "source": [
        "You may have noticed a button labeled \"Explode\". Don't click that, as it will set off a small bomb underneath your humble author's desk in the W&B HQ!\n",
        "\n",
        "Just kidding. It \"explodes\" the graph in a much gentler way:\n",
        "`Artifact`s and `Run`s become separated at the level of a single instance,\n",
        "rather than a `type`:\n",
        "the nodes are not `dataset` and `load-data`, but `dataset:mnist-raw:v1` and `load-data:sunny-smoke-1`, and so on.\n",
        "\n",
        "This provides total insight into your pipeline,\n",
        "with logged metrics, metadata, and more\n",
        "all at your fingertips --\n",
        "you're only limited by what you choose to log with us."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9a10867b8c544037ac5620b26de3ddd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_93d1e909b82c46fabac9cffbe288d750",
              "IPY_MODEL_0a5d4742726e4f03840dbd0fdf6c9f93"
            ],
            "layout": "IPY_MODEL_edcdaec46efb44f7baa57b1b5783589f"
          }
        },
        "93d1e909b82c46fabac9cffbe288d750": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec2fbacfc40f422f93a562f74cc8d5f0",
            "placeholder": "​",
            "style": "IPY_MODEL_d8356e624ce740f5859858d1babcde61",
            "value": "98.207 MB of 98.207 MB uploaded\r"
          }
        },
        "0a5d4742726e4f03840dbd0fdf6c9f93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65e32ff5e78c4423a42b24765b2f38c5",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e8fa0cec6a384a9cb0125d9e40fdc7fc",
            "value": 1
          }
        },
        "edcdaec46efb44f7baa57b1b5783589f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec2fbacfc40f422f93a562f74cc8d5f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8356e624ce740f5859858d1babcde61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "65e32ff5e78c4423a42b24765b2f38c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8fa0cec6a384a9cb0125d9e40fdc7fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ce2b1d34bd21418ba0de0fad005820ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_80face98f71c4e1096987b8b1a7c2908",
              "IPY_MODEL_7e9f4becee8942c7bfee583ea63ab0c8"
            ],
            "layout": "IPY_MODEL_efc74ee2e30c4c4aaf8b803fe26b85b2"
          }
        },
        "80face98f71c4e1096987b8b1a7c2908": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0edd187e40f949f6949409e116a66bbe",
            "placeholder": "​",
            "style": "IPY_MODEL_9db2630765534d65b9c8b4bbc46fed3d",
            "value": "210.359 MB of 210.359 MB uploaded\r"
          }
        },
        "7e9f4becee8942c7bfee583ea63ab0c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9a24284eac340d28aa18834c9a9b9f6",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b246166afe70458ebe8352261edbaedf",
            "value": 1
          }
        },
        "efc74ee2e30c4c4aaf8b803fe26b85b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0edd187e40f949f6949409e116a66bbe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9db2630765534d65b9c8b4bbc46fed3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d9a24284eac340d28aa18834c9a9b9f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b246166afe70458ebe8352261edbaedf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cb863233033f4440bf8018dd5325db79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ad573ae8347a458e9dd9eaa05be9ef07",
              "IPY_MODEL_10089b3fb8374a47b86949a0adb682c0"
            ],
            "layout": "IPY_MODEL_f7caecee87b34508baa19d98fb7340f6"
          }
        },
        "ad573ae8347a458e9dd9eaa05be9ef07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae598b72c6714146b6ae61e08192b68c",
            "placeholder": "​",
            "style": "IPY_MODEL_415cbbb9a3dd4b4dacf7aba2f3aebada",
            "value": "0.283 MB of 0.283 MB uploaded\r"
          }
        },
        "10089b3fb8374a47b86949a0adb682c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad0b4610179e45e5a1dd56e596d4dcca",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_24d94887e9544356a99c5640f9da0d59",
            "value": 1
          }
        },
        "f7caecee87b34508baa19d98fb7340f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae598b72c6714146b6ae61e08192b68c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "415cbbb9a3dd4b4dacf7aba2f3aebada": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad0b4610179e45e5a1dd56e596d4dcca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24d94887e9544356a99c5640f9da0d59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6f40d2162201456194b8bf7157126dec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5754ce43613e48c8b150e0f995e53790",
              "IPY_MODEL_918799ce377946bc99bef56be4bc2be9"
            ],
            "layout": "IPY_MODEL_8705ed3d9fc449439788f193eff9dbb0"
          }
        },
        "5754ce43613e48c8b150e0f995e53790": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_015769be45ce4792a9ff37c78ff379a4",
            "placeholder": "​",
            "style": "IPY_MODEL_f577f7748c35489aa15930476c4407fa",
            "value": "0.292 MB of 0.292 MB uploaded\r"
          }
        },
        "918799ce377946bc99bef56be4bc2be9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de006a676c3f481eae25f4ed4286a383",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3ccf7a2a31154c339b793ecf48173068",
            "value": 1
          }
        },
        "8705ed3d9fc449439788f193eff9dbb0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "015769be45ce4792a9ff37c78ff379a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f577f7748c35489aa15930476c4407fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de006a676c3f481eae25f4ed4286a383": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ccf7a2a31154c339b793ecf48173068": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5c136a77191c4bcf8d8c64824ff091f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_db5dde5ee28540c5b2e201249f0db271",
              "IPY_MODEL_c33a853aa24f4d99bc464f832221539d"
            ],
            "layout": "IPY_MODEL_4317dd43dd7e4b8f8b338cff9f623303"
          }
        },
        "db5dde5ee28540c5b2e201249f0db271": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bbb04154da694df195782fde18dc0726",
            "placeholder": "​",
            "style": "IPY_MODEL_be51d8aa88cd4993a822c732f6a41f94",
            "value": "0.029 MB of 0.029 MB uploaded\r"
          }
        },
        "c33a853aa24f4d99bc464f832221539d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1b7727570104e49bc7f5152f6d86ec4",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_78872de69daa4a38a48f58ce59e55037",
            "value": 1
          }
        },
        "4317dd43dd7e4b8f8b338cff9f623303": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbb04154da694df195782fde18dc0726": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be51d8aa88cd4993a822c732f6a41f94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1b7727570104e49bc7f5152f6d86ec4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78872de69daa4a38a48f58ce59e55037": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}